# 爬虫基础课01

标签（空格分隔）： Clawer

---

一、 数据获取方式
1. 企业生产用户数据： 大型互联网公司有海量用户，积累数据有天然优势；
有数据意识的中小型企业，开始积累的数据；
2. 数据管理咨询公司：一般会通过市场调研，固定的样本检测
百度指数，阿里指数， 微指数，腾讯浏览指数
3. 政府机构提供的公开数据：
National Data国家数据，The world bank，Nasdaq， UNdata
4. 第三方数据平台购买数据：通过各个数据交易平台来购买各行各业需要的数据
数据堂，贵阳大数据交易所
5. 爬虫爬取数据：定向采集数据

二、 什么是爬虫
就是抓取网页数据的程序；

三、 爬虫是怎么抓取网页数据：

网页三大特征：
1. 唯一的URL来进行定位，统一资源定位符；
2. HTML（超文本标记语言）来描述页面信息；
3. 网页HTTP、HTTPS协议来传输HTML数据；

爬虫的设计思路：
1. 确定需要爬取的URL地址；
2. 通过HTTP获取HTML页面；
3. 提取HTML有用数据；

四、 为什么选择Python

PHP、JAVA、C/C++、Python
- PHP对多线程、异步爬虫支持不好，生态圈小；
- JAVA语言本身笨重，代码量大，重构成本高，生态圈很完善；
- C/C++运行效率和性能几乎最强，学习成本高，代码成型慢；

Scrapy爬虫，scrapy-redis分布式策略；

 五、课程介绍

1. 抓取HTML：
http请求处理，urllib、urllib2、requests；
2. 解析服务器响应内容：
re、xpath、BeautifulSoup4、jsonpath、pyquery等；
3. 采集动态HTML、验证码处理：
动态页面采集：Selenium + PhantomJS（无界面），模拟真实浏览器加载；
Tesseract: 机器学习库，机器图像识别系统；
打码平台（验证码识别） ；
4. Scrapy框架（Pyspider）：
高定制性高性能（异步网络框架twisted），数据下载速度非常快，提供了数据存储、数据下载、提取规则等组件；
5. 分布式策略：
scrapy-redis，以Redis数据库为核心的一套组件；
scrapy框架支持分布式功能，主要在Redis里做请求指纹去重、请求分配、数据临时存储；
6. 爬虫、反爬虫、反反爬虫；
User Agent、 IP代理、 验证码、 动态页面加载、加密数据（在某个JS脚本中）；

六、 通用爬虫 聚焦爬虫

以上根据使用场景分类；

DNS：域名解析IP
链接提交
搜索引擎与DNS服务商合作（DNSPod）

Robots.txt 并不是所有爬虫都遵守，一般只有大型搜索引擎爬虫遵守；

- 爬虫工作流程

爬取网页 -> 存储数据 -> 内容处理 -> 提供检索/排名服务；

- 搜索引擎排名：

PageRank值：根据网站流量统计（点击量/浏览量/人气），流量越高，排名越靠前；
竞价排名

- 通用爬虫缺点：

只能提供和文本内容，不能提供多媒体文件和二进制文件；
提供的结果千篇一律，不能针对不同背景领域的人提供不同的搜索结果；
不能理解人类语义上的检索；

- 聚焦爬虫

面向主题爬虫，面向需求，会针对某种特定内容去爬取信息；

